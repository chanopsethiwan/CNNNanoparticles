{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') #choose whether to use gpu or cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA STANDARDIZATION\n",
    "\n",
    "# import libraries\n",
    "import os\n",
    "import shutil\n",
    "from collections import defaultdict \n",
    "\n",
    "# Directories\n",
    "# change to the [AgNO3][NaBH4] kinetic filter directory\n",
    "targetDir = r'C:\\Users\\Public\\PartIIB project 2023_2024\\Image collection without reaction\\00AgNO3_mole_fraction\\Outputs_Grayscale_Labelled_Images_Sizes\\size_folder3'\n",
    "input_folder = r'C:\\Users\\Public\\PartIIB project 2023_2024\\Image collection without reaction\\00AgNO3_mole_fraction\\Outputs_Grayscale_Labelled_Images_Sizes\\size_folder'\n",
    "output_folder_train = r'C:\\Users\\Public\\PartIIB project 2023_2024\\Image collection without reaction\\00AgNO3_mole_fraction\\dataSelectorHelical5\\train'\n",
    "output_folder_test_val = r'C:\\Users\\Public\\PartIIB project 2023_2024\\Image collection without reaction\\00AgNO3_mole_fraction\\dataSelectorHelical5\\testVal'\n",
    "output_folder_test_val_disc = r'C:\\Users\\Public\\PartIIB project 2023_2024\\Image collection without reaction\\00AgNO3_mole_fraction\\dataSelectorHelical5\\testValDisc'\n",
    "\n",
    "# Self-define parameters\n",
    "\n",
    "# number of image in input\n",
    "input_num = 1\n",
    "\n",
    "# number of size bins\n",
    "num_bins = 68\n",
    "\n",
    "# disrgardFactor x x_avg (average number of contours per bin) = the upper limit such that any bin with lower than this number is discarded\n",
    "disregardFactor = 0.5\n",
    "\n",
    "# propotion of data that will be used for traning given disrgardFactor x x_avg < x < x_avg x upperFactor / train_proportion\n",
    "trainProportion = 0.8\n",
    "\n",
    "# x_avg x upperFactor / train_proportion = below this number take 80% to train and above this number take x_avg x upperFactor to train\n",
    "upperFactor = 2\n",
    "\n",
    "# the size range of each bin\n",
    "bin_width = 0.5\n",
    "\n",
    "\n",
    "def obtainSizeRange(targetDir, input_num, num_bins):\n",
    "    lstDir = os.listdir(targetDir)    \n",
    "    numLst = [i/2 for i in range(num_bins)]\n",
    "    sizeDict = {}\n",
    "    for j in numLst:\n",
    "      sizeDict[j] = 0\n",
    "    for i in lstDir:\n",
    "        t_number = int(i.split(\"t-\")[1].split(\"_\")[0])\n",
    "        lowerT = 200 - (200/input_num) + 1\n",
    "        if lowerT <= t_number <= 200:\n",
    "            size = float(i[-17:-5])\n",
    "            sizeRange = int(size*2)/2\n",
    "            sizeDict[sizeRange] += 1\n",
    "\n",
    "    print(sizeDict)\n",
    "    print(dict(sorted(sizeDict.items())))\n",
    "    print(dict(sorted(sizeDict.items(), key=lambda item: item[1])))\n",
    "    return dict(sorted(sizeDict.items()))\n",
    "\n",
    "sizeDict = obtainSizeRange(targetDir = targetDir, input_num= input_num, num_bins= num_bins)\n",
    "\n",
    "def obtainDesiredDict(sizeDict, disregardFactor, trainProportion, upperFactor):\n",
    "    # get avg\n",
    "    numLst = [i/2 for i in range(len(sizeDict)+1)]\n",
    "\n",
    "    counter = 0\n",
    "    for j in numLst:\n",
    "        try:\n",
    "            counter += sizeDict[j]\n",
    "        except KeyError:\n",
    "            pass    \n",
    "    x_avg = counter/(len(numLst))\n",
    "    \n",
    "    \n",
    "    \n",
    "    desiredDict = {}\n",
    "    x_lower = x_avg*disregardFactor\n",
    "    x_upper = (x_avg*upperFactor)/trainProportion\n",
    "    numLst = [i/2 for i in range(len(sizeDict)+1)]\n",
    "    \n",
    "    for j in numLst:\n",
    "        try:\n",
    "            # x = number of contours per bin\n",
    "            x = sizeDict[j]\n",
    "            \n",
    "            if x < x_lower:\n",
    "                desiredDict[j] = 0\n",
    "            \n",
    "            if x_lower < x < x_upper:\n",
    "                desiredDict[j] = int(trainProportion*x)\n",
    "                \n",
    "            if x > x_upper:\n",
    "                desiredDict[j] = int(x_avg*upperFactor)\n",
    "                \n",
    "        except KeyError:\n",
    "            pass\n",
    "    return desiredDict\n",
    "\n",
    "desiredDict = obtainDesiredDict(sizeDict, disregardFactor= disregardFactor, trainProportion= trainProportion, upperFactor= upperFactor)\n",
    "\n",
    "def data_standardisation(input_folder, output_folder_train, output_folder_test_val, output_folder_test_val_disc, desiredDict, input_num, bin_width):\n",
    "   \n",
    "   last_time_section = ((input_num-1)/(input_num))*200\n",
    "   os.makedirs(output_folder_train, exist_ok=True)\n",
    "   os.makedirs(output_folder_test_val, exist_ok=True)\n",
    "   os.makedirs(output_folder_test_val_disc, exist_ok=True)\n",
    "   \n",
    "   \n",
    "   # create the counter dictionary\n",
    "   numLst = [i/2 for i in range(len(desiredDict))]\n",
    "   counterDict = {}\n",
    "   for j in numLst:\n",
    "      counterDict[j] = 0\n",
    "      \n",
    "   \n",
    "   for filename in os.listdir(input_folder):\n",
    "      size = float(filename[-17:-5])\n",
    "      t_number = int(filename.split(\"t-\")[1].split(\"_\")[0])\n",
    "      if t_number > last_time_section:\n",
    "         for j in numLst:\n",
    "            if j < size < j+bin_width:\n",
    "               if counterDict[j] < desiredDict[j]:\n",
    "                  input_filepath = os.path.join(input_folder, filename)\n",
    "                  output_filepath = os.path.join(output_folder_train, filename)\n",
    "                  shutil.copy(input_filepath, output_filepath)\n",
    "                  counterDict[j] += 1\n",
    "                  for j in range(input_num-1):\n",
    "                        fig_number = filename.split(\"_\")[1]\n",
    "                        # print(fig_number)\n",
    "                        t_number_new = str(int(t_number-(j+1)*(200/input_num)))\n",
    "                        # print(t_number_new)\n",
    "                        # print(f\"Fig_{fig_number}__t-{t_number_new}\")\n",
    "                        filename_new = [item for item in os.listdir(input_folder) if item.startswith(f\"Fig_{fig_number}__t-{t_number_new}\")][0]\n",
    "                        # print(filename_new)\n",
    "                        input_filepath = os.path.join(input_folder, filename_new)\n",
    "                        output_filepath = os.path.join(output_folder_train, filename_new)\n",
    "                        shutil.copy(input_filepath, output_filepath)\n",
    "   for filename2 in os.listdir(input_folder):\n",
    "      if filename2 not in os.listdir(output_folder_train):\n",
    "         for j in numLst:\n",
    "            if j < size < j+bin_width:\n",
    "               if obtainDesiredDict[j] == 0:\n",
    "                  input_filepath = os.path.join(input_folder, filename2)\n",
    "                  output_filepath = os.path.join(output_folder_test_val_disc, filename2)\n",
    "                  shutil.copy(input_filepath, output_filepath)\n",
    "               else:\n",
    "                  input_filepath = os.path.join(input_folder, filename2)\n",
    "                  output_filepath = os.path.join(output_folder_test_val, filename2)\n",
    "                  shutil.copy(input_filepath, output_filepath)\n",
    "      \n",
    "               \n",
    "\n",
    "data_standardisation(input_folder=input_folder, output_folder_train=output_folder_train, output_folder_test_val=output_folder_test_val, desiredDict=desiredDict, input_num=input_num, bin_width= bin_width) \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = r'C:\\Users\\Public\\PartIIB project 2023_2024\\Image collection without reaction\\00AgNO3_mole_fraction\\Outputs_Grayscale_Labelled_Images_Sizes\\size_folder'\n",
    "# for this we need to use [AgNO3][NaBH4] kinetic filter contours to be able to compare direcly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.images = sorted([f for f in os.listdir(root_dir) if os.path.isfile(os.path.join(root_dir, f))]) #this excludes folder as well\n",
    "        self.labels = [self.extract_label(img) for img in self.images]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = os.path.join(self.root_dir, self.images[idx])\n",
    "        image = Image.open(img_name)\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        label = self.labels[idx]\n",
    "        return image, label\n",
    "\n",
    "    def extract_label(self, img_name):\n",
    "        # Assuming that the label is part of the filename before the first underscore\n",
    "        label = float(img_name[-17:-5]) #this is the right code\n",
    "        # label = img_name\n",
    "        return label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transform = transforms.Compose(\n",
    "[transforms.ToTensor(),\n",
    "transforms.Normalize((0.45), (0.25))]) \n",
    "\n",
    "custom_dataset = CustomImageDataset(root_dir=data_dir, transform=data_transform)\n",
    "\n",
    "# # Accessing the data\n",
    "# for img, label in custom_dataset:\n",
    "#     print(f\"Image shape: {img.shape}, Label: {label}\")\n",
    "\n",
    "print(len(custom_dataset))\n",
    "# train_set, val_set, test_set = random_split(custom_dataset, [int(len(custom_dataset)*0.75), int(len(custom_dataset)*0.15), int(len(custom_dataset)*0.100056)]) #splits data into training, validation and test sets\n",
    "train_set, test_set = random_split(custom_dataset, [int(len(custom_dataset)*0.75), int(len(custom_dataset)*0.25003)])\n",
    "print(len(train_set))\n",
    "# print(len(val_set))\n",
    "print(len(test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hyper parameters\n",
    "# num_epochs = 30\n",
    "num_epochs = 60\n",
    "batch_size = 1\n",
    "learning_rate = 0.0005\n",
    "# learning_rate = 0.001\n",
    "\n",
    "train = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
    "# val = DataLoader(val_set, batch_size=batch_size, shuffle=False)\n",
    "test = DataLoader(test_set, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module): # note need to find out image size\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1,8,10, padding='same') #in_channels, out_channels, kernel_size\n",
    "        self.normalise1 = nn.BatchNorm2d(8)\n",
    "        # self.pool = nn.MaxPool2d(5,5) #kernel_size, stride (shift x pixel to the right)\n",
    "        # self.pool1 = nn.AvgPool2d(10, stride=10) \n",
    "        self.pool1 = nn.MaxPool2d(10, stride=10)\n",
    "        self.conv2 = nn.Conv2d(8, 16, 10, padding='same')\n",
    "        self.normalise2 = nn.BatchNorm2d(16)\n",
    "        # self.pool2 = nn.AvgPool2d(2, stride=2)\n",
    "        self.pool2 = nn.MaxPool2d(2, stride=2)\n",
    "        self.conv3 = nn.Conv2d(16, 32, 10, padding='same')\n",
    "        self.normalise3 = nn.BatchNorm2d(32) \n",
    "        self.conv4 = nn.Conv2d(32, 32, 10, padding='same')\n",
    "        # self.fc1 = nn.Linear(16*3*3, 120) # 3x3 is the size of the image after 2 conv layers, 16 is the number of channels, 120 is the number of nodes in the hidden layer\n",
    "        # self.fc2 = nn.Linear(120,84)\n",
    "        # self.fc3 = nn.Linear(60, 1)\n",
    "        self.fc = nn.Linear(32*5*5, 1)\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool1(F.relu(self.normalise1(self.conv1(x)))) \n",
    "        x = self.pool2(F.relu(self.normalise2(self.conv2(x)))) \n",
    "        x = F.relu(self.normalise3(self.conv3(x)))\n",
    "        x = F.relu(self.normalise3(self.conv4(x)))\n",
    "        x = F.relu(self.normalise3(self.conv4(x)))\n",
    "        x = x.view(-1, 32*5*5)  #flatten\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ConvNet().to(device)\n",
    "\n",
    "# loss and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "#training loop\n",
    "n_total_steps = len(train)\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        #forward\n",
    "        outputs = model(images)\n",
    "        labels = labels.float()\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        #backward\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if (i+1) % 10 ==0:\n",
    "            print(f'epoch {epoch+1}/{num_epochs}, step {i+1}/{n_total_steps}, loss = {loss.item():.4f}')\n",
    "\n",
    "print(\"Finished Training\")\n",
    "\n",
    "#test \n",
    "#need to change testing to be based on continuous value\n",
    "with torch.no_grad(): # no need to calculate gradient\n",
    "    squared_difference = 0\n",
    "    for images, labels in test:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        \n",
    "        #value, index\n",
    "        _, predictions = torch.max(outputs, 1)\n",
    "        squared_difference += (predictions - labels) ** 2\n",
    "    \n",
    "    rmse = torch.sqrt(squared_difference / len(test))\n",
    "    print(f'RMSE = {rmse}')\n",
    "\n",
    "#Data set is split into training and test sets (85% and 15%)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
