{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader, random_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') #choose whether to use gpu or cpu\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_dir = r'C:\\Users\\Public\\PartIIB project 2023_2024\\Image collection without reaction\\00AgNO3_mole_fraction\\Outputs_Grayscale_Labelled_Images_Sizes\\size_folder'  #path to the folder containing the images\n",
    "# data_dir = r'C:\\Users\\Public\\PartIIB project 2023_2024\\PastData\\helical_size'\n",
    "data_dir = r'C:\\Users\\Public\\PartIIB project 2023_2024\\Image collection without reaction\\00AgNO3_mole_fraction\\Outputs_Grayscale_Labelled_Images_Sizes\\size_folder\\second_half'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "# dataset with cutsize \n",
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.images = sorted(os.listdir(root_dir))\n",
    "        self.labels = [self.extract_label(img) for img in self.images]\n",
    "        self.cuttime = [self.extract_cuttime(img) for img in self.images]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = os.path.join(self.root_dir, self.images[idx])\n",
    "        image = Image.open(img_name)\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        label = self.labels[idx]\n",
    "        cuttime = self.cuttime[idx]\n",
    "        return image, label, cuttime\n",
    "\n",
    "    def extract_label(self, img_name):\n",
    "        # Assuming that the label is part of the filename before the first underscore\n",
    "        label = float(img_name[-17:-5]) #this is the right code\n",
    "        # label = img_name\n",
    "        return label\n",
    "    \n",
    "    def extract_cuttime(self, img_name):\n",
    "        cuttime = int(img_name.split(\"t-\")[1].split(\"_\")[0])\n",
    "        return cuttime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'os' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/chap/CNNNanoparticles/timeInputTest.ipynb Cell 5\u001b[0m line \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/chap/CNNNanoparticles/timeInputTest.ipynb#W6sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m data_transform \u001b[39m=\u001b[39m transforms\u001b[39m.\u001b[39mCompose(\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/chap/CNNNanoparticles/timeInputTest.ipynb#W6sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m [transforms\u001b[39m.\u001b[39mToTensor(),\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/chap/CNNNanoparticles/timeInputTest.ipynb#W6sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m transforms\u001b[39m.\u001b[39mNormalize((\u001b[39m0.45\u001b[39m), (\u001b[39m0.25\u001b[39m))]) \n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/chap/CNNNanoparticles/timeInputTest.ipynb#W6sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m custom_dataset \u001b[39m=\u001b[39m CustomImageDataset(root_dir\u001b[39m=\u001b[39;49mdata_dir, transform\u001b[39m=\u001b[39;49mdata_transform)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/chap/CNNNanoparticles/timeInputTest.ipynb#W6sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39m# # Accessing the data\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/chap/CNNNanoparticles/timeInputTest.ipynb#W6sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39m# for img, label in custom_dataset:\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/chap/CNNNanoparticles/timeInputTest.ipynb#W6sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39m#     print(f\"Image shape: {img.shape}, Label: {label}\")\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/chap/CNNNanoparticles/timeInputTest.ipynb#W6sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mlen\u001b[39m(custom_dataset))\n",
      "\u001b[1;32m/Users/chap/CNNNanoparticles/timeInputTest.ipynb Cell 5\u001b[0m line \u001b[0;36mCustomImageDataset.__init__\u001b[0;34m(self, root_dir, transform)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/chap/CNNNanoparticles/timeInputTest.ipynb#W6sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mroot_dir \u001b[39m=\u001b[39m root_dir\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/chap/CNNNanoparticles/timeInputTest.ipynb#W6sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransform \u001b[39m=\u001b[39m transform\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/chap/CNNNanoparticles/timeInputTest.ipynb#W6sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mimages \u001b[39m=\u001b[39m \u001b[39msorted\u001b[39m(os\u001b[39m.\u001b[39mlistdir(root_dir))\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/chap/CNNNanoparticles/timeInputTest.ipynb#W6sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlabels \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mextract_label(img) \u001b[39mfor\u001b[39;00m img \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mimages]\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/chap/CNNNanoparticles/timeInputTest.ipynb#W6sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcuttime \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mextract_cuttime(img) \u001b[39mfor\u001b[39;00m img \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mimages]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'os' is not defined"
     ]
    }
   ],
   "source": [
    "data_transform = transforms.Compose(\n",
    "[transforms.ToTensor(),\n",
    "transforms.Normalize((0.45), (0.25))]) \n",
    "\n",
    "custom_dataset = CustomImageDataset(root_dir=data_dir, transform=data_transform)\n",
    "\n",
    "# # Accessing the data\n",
    "# for img, label in custom_dataset:\n",
    "#     print(f\"Image shape: {img.shape}, Label: {label}\")\n",
    "\n",
    "print(len(custom_dataset))\n",
    "# train_set, val_set, test_set = random_split(custom_dataset, [int(len(custom_dataset)*0.75), int(len(custom_dataset)*0.15), int(len(custom_dataset)*0.100056)]) #splits data into training, validation and test sets\n",
    "train_set, test_set = random_split(custom_dataset, [int(len(custom_dataset)*0.75), int(len(custom_dataset)*0.25003)])\n",
    "print(len(train_set))\n",
    "# print(len(val_set))\n",
    "print(len(test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_set' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/chap/CNNNanoparticles/timeInputTest.ipynb Cell 5\u001b[0m line \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/chap/CNNNanoparticles/timeInputTest.ipynb#W4sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m learning_rate \u001b[39m=\u001b[39m \u001b[39m0.0005\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/chap/CNNNanoparticles/timeInputTest.ipynb#W4sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39m# learning_rate = 0.001\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/chap/CNNNanoparticles/timeInputTest.ipynb#W4sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m train \u001b[39m=\u001b[39m DataLoader(train_set, batch_size\u001b[39m=\u001b[39mbatch_size, shuffle\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/chap/CNNNanoparticles/timeInputTest.ipynb#W4sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39m# val = DataLoader(val_set, batch_size=batch_size, shuffle=False)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/chap/CNNNanoparticles/timeInputTest.ipynb#W4sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m test \u001b[39m=\u001b[39m DataLoader(test_set, batch_size\u001b[39m=\u001b[39mbatch_size, shuffle\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_set' is not defined"
     ]
    }
   ],
   "source": [
    "#hyper parameters\n",
    "# num_epochs = 30\n",
    "num_epochs = 60\n",
    "batch_size = 1\n",
    "learning_rate = 0.0005\n",
    "# learning_rate = 0.001\n",
    "\n",
    "train = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
    "# val = DataLoader(val_set, batch_size=batch_size, shuffle=False)\n",
    "test = DataLoader(test_set, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "class ConvNet(nn.Module): # note need to find out image size\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1,8,10, padding='same') #in_channels, out_channels, kernel_size\n",
    "        self.normalise1 = nn.BatchNorm2d(8)\n",
    "        # self.pool = nn.MaxPool2d(5,5) #kernel_size, stride (shift x pixel to the right)\n",
    "        # self.pool1 = nn.AvgPool2d(10, stride=10)\n",
    "        self.pool1 = nn.MaxPool2d(10, stride=10)\n",
    "        self.conv2 = nn.Conv2d(8, 16, 10, padding='same')\n",
    "        self.normalise2 = nn.BatchNorm2d(16)\n",
    "        # self.pool2 = nn.AvgPool2d(2, stride=2)\n",
    "        self.pool2 = nn.MaxPool2d(2, stride=2)\n",
    "        self.conv3 = nn.Conv2d(16, 32, 10, padding='same')\n",
    "        self.normalise3 = nn.BatchNorm2d(32) \n",
    "        self.conv4 = nn.Conv2d(32, 32, 10, padding='same')\n",
    "        # self.fc1 = nn.Linear(16*3*3, 120) # 3x3 is the size of the image after 2 conv layers, 16 is the number of channels, 120 is the number of nodes in the hidden layer\n",
    "        # self.fc2 = nn.Linear(120,84)\n",
    "        # self.fc3 = nn.Linear(60, 1)\n",
    "        self.fc = nn.Linear(32*5*5, 1)\n",
    "        self.fc1 = nn.Linear(32*5*5, 400)\n",
    "        self.fc2 = nn.Linear(400,200)\n",
    "        self.fc3 = nn.Linear(200,1)\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool1(F.relu(self.normalise1(self.conv1(x)))) \n",
    "        x = self.pool2(F.relu(self.normalise2(self.conv2(x)))) \n",
    "        x = F.relu(self.normalise3(self.conv3(x)))\n",
    "        x = F.relu(self.normalise3(self.conv4(x)))\n",
    "        x = F.relu(self.normalise3(self.conv4(x)))\n",
    "        x = x.view(-1, 32*5*5)  #flatten\n",
    "        x = F.relu(self.fc1(x))\n",
    "        # x = self.fc2(x)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        # x = self.fc(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
