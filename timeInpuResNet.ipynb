{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torch import Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') #choose whether to use gpu or cpu\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = r'C:\\Users\\Public\\PartIIB project 2023_2024\\Image collection without reaction\\00AgNO3_mole_fraction\\Outputs_Grayscale_Labelled_Images_Sizes\\size_folder'  #path to the folder containing the images\n",
    "# data_dir = r'C:\\Users\\Public\\PartIIB project 2023_2024\\PastData\\helical_size'\n",
    "# data_dir = r'C:\\Users\\Public\\PartIIB project 2023_2024\\Image collection without reaction\\00AgNO3_mole_fraction\\Outputs_Grayscale_Labelled_Images_Sizes\\size_folder\\second_half'\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "# data_dir = \"/content/drive/My Drive/size_folder\" #colab path\n",
    "# data_dir = r'C:\\Users\\Chappyyyyyy\\Documents\\size_folder' #path to folder for chappy computer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "# dataset with cutsize \n",
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.images = sorted([f for f in os.listdir(root_dir) if os.path.isfile(os.path.join(root_dir, f))])\n",
    "        self.labels = [self.extract_label(img) for img in self.images]\n",
    "        self.cuttime = [self.extract_cuttime(img) for img in self.images]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = os.path.join(self.root_dir, self.images[idx])\n",
    "        image = Image.open(img_name)\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        label = self.labels[idx]\n",
    "        cuttime = self.cuttime[idx]\n",
    "        return image, label, cuttime\n",
    "\n",
    "    def extract_label(self, img_name):\n",
    "        # Assuming that the label is part of the filename before the first underscore\n",
    "        label = float(img_name[-17:-5]) #this is the right code\n",
    "        # label = img_name\n",
    "        return label\n",
    "    \n",
    "    def extract_cuttime(self, img_name):\n",
    "        cuttime = float(img_name.split(\"t-\")[1].split(\"_\")[0])\n",
    "        return cuttime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15800\n",
      "11850\n",
      "3950\n"
     ]
    }
   ],
   "source": [
    "data_transform = transforms.Compose(\n",
    "[transforms.ToTensor(),\n",
    "transforms.Normalize((0.5,), (0.5,))]) \n",
    "\n",
    "custom_dataset = CustomImageDataset(root_dir=data_dir, transform=data_transform)\n",
    "\n",
    "# # Accessing the data\n",
    "# for img, label in custom_dataset:\n",
    "#     print(f\"Image shape: {img.shape}, Label: {label}\")\n",
    "\n",
    "print(len(custom_dataset))\n",
    "# train_set, val_set, test_set = random_split(custom_dataset, [int(len(custom_dataset)*0.75), int(len(custom_dataset)*0.15), int(len(custom_dataset)*0.100056)]) #splits data into training, validation and test sets\n",
    "train_set, test_set = random_split(custom_dataset, [int(len(custom_dataset)*0.75), int(len(custom_dataset)*0.25003)])\n",
    "print(len(train_set))\n",
    "# print(len(val_set))\n",
    "print(len(test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.009037\n",
      "92.0\n",
      "[tensor([[[[-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "          ...,\n",
      "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "          [-1., -1., -1.,  ..., -1., -1., -1.]]]]), tensor([23.3589], dtype=torch.float64), tensor([73.], dtype=torch.float64)]\n"
     ]
    }
   ],
   "source": [
    "#hyper parameters\n",
    "num_epochs = 30\n",
    "# num_epochs = 60\n",
    "batch_size = 1\n",
    "learning_rate = 0.0005\n",
    "# learning_rate = 0.001\n",
    "\n",
    "train = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
    "# val = DataLoader(val_set, batch_size=batch_size, shuffle=False)\n",
    "test = DataLoader(test_set, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "for (images, labels, cuttime) in train:\n",
    "    print(labels.item())\n",
    "    print(cuttime.item())\n",
    "    break\n",
    "\n",
    "for i in train:\n",
    "    print(i)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#residual block class\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels: int, out_channels: int) -> None:\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_channels=in_channels, \n",
    "            out_channels=out_channels, \n",
    "            kernel_size=(3, 3), \n",
    "            padding='same', \n",
    "            bias=False\n",
    "        )\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.conv2 = nn.Conv2d(\n",
    "            in_channels=out_channels, \n",
    "            out_channels=out_channels, \n",
    "            kernel_size=(3, 3), \n",
    "            padding='same', \n",
    "            bias=False\n",
    "        )\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        \n",
    "        self.downsample = None\n",
    "        if in_channels != out_channels:\n",
    "            self.downsample = nn.Sequential(\n",
    "                nn.Conv2d(\n",
    "                    in_channels, \n",
    "                    out_channels, \n",
    "                    kernel_size=(3, 3), \n",
    "                    padding='same', \n",
    "                    bias=False\n",
    "                ),\n",
    "                nn.BatchNorm2d(out_channels)\n",
    "            )\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        identity = self.downsample(x) if self.downsample else x\n",
    "        \n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.relu(x + identity)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet34(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ResNet34,self).__init__()\n",
    "        \n",
    "        self.block1 = nn.Sequential(\n",
    "            nn.Conv2d(1,64,kernel_size=2,stride=2,padding=3,bias=False),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(True)\n",
    "        )\n",
    "        \n",
    "        self.block2 = nn.Sequential(\n",
    "            nn.AvgPool2d(1,1),\n",
    "            ResidualBlock(64,64),\n",
    "            ResidualBlock(64,64),\n",
    "            nn.AvgPool2d(kernel_size=(2, 2), stride=(2, 2))\n",
    "        )\n",
    "        \n",
    "        self.block3 = nn.Sequential(\n",
    "            ResidualBlock(64,128),\n",
    "            ResidualBlock(128,128),\n",
    "            nn.AvgPool2d(kernel_size=(2, 2), stride=(2, 2))\n",
    "        )\n",
    "        \n",
    "        self.block4 = nn.Sequential(\n",
    "            ResidualBlock(128,256),\n",
    "            ResidualBlock(256,256),\n",
    "            nn.AvgPool2d(kernel_size=(2, 2), stride=(2, 2))\n",
    "        )\n",
    "        self.block5 = nn.Sequential(\n",
    "            ResidualBlock(256,512),\n",
    "            ResidualBlock(512,512),\n",
    "            nn.AvgPool2d(kernel_size=(2, 2), stride=(2, 2))\n",
    "        )\n",
    "        \n",
    "        self.Avgpool = nn.AvgPool2d(2)\n",
    "        # vowel_diacritic\n",
    "        self.fc1 = nn.Linear(512+5,128)\n",
    "        # grapheme_root\n",
    "        self.fc2 = nn.Linear(128,64)\n",
    "        # consonant_diacritic\n",
    "        self.fc3 = nn.Linear(64,1)\n",
    "        self.fc = nn.Linear(1,1)\n",
    "        \n",
    "    def forward(self,x, y):\n",
    "        x = self.block1(x)\n",
    "        x = self.block2(x)\n",
    "        x = self.block3(x)\n",
    "        x = self.block4(x)\n",
    "        x = self.block5(x)\n",
    "        x = self.Avgpool(x)\n",
    "        x = x.view(x.size(0),-1)\n",
    "        y = self.fc(y)\n",
    "        y = y.view(-1, 1).repeat(1,5)\n",
    "\n",
    "        z = torch.cat((x,y), dim=1)\n",
    "        z = F.relu(self.fc1(z))\n",
    "        z = F.relu(self.fc2(z))\n",
    "        z = self.fc3(z)\n",
    "        return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1/30, average loss = 41.1992\n",
      "epoch 2/30, average loss = 28.9726\n",
      "epoch 3/30, average loss = 23.3563\n",
      "epoch 4/30, average loss = 18.8641\n",
      "epoch 5/30, average loss = 15.5626\n",
      "epoch 6/30, average loss = 13.3323\n",
      "epoch 7/30, average loss = 11.9692\n",
      "epoch 8/30, average loss = 10.7381\n",
      "epoch 9/30, average loss = 10.1678\n",
      "epoch 10/30, average loss = 9.3967\n",
      "epoch 11/30, average loss = 9.0805\n",
      "epoch 12/30, average loss = 8.5740\n",
      "epoch 13/30, average loss = 8.1461\n",
      "epoch 14/30, average loss = 7.8296\n",
      "epoch 15/30, average loss = 7.8006\n",
      "epoch 16/30, average loss = 7.5963\n",
      "epoch 17/30, average loss = 7.4060\n",
      "epoch 18/30, average loss = 6.9936\n",
      "epoch 19/30, average loss = 7.0832\n",
      "epoch 20/30, average loss = 6.9160\n",
      "epoch 21/30, average loss = 6.7785\n",
      "epoch 22/30, average loss = 6.7006\n",
      "epoch 23/30, average loss = 6.5159\n",
      "epoch 24/30, average loss = 6.5294\n",
      "epoch 25/30, average loss = 6.4719\n",
      "epoch 26/30, average loss = 6.4583\n",
      "epoch 27/30, average loss = 6.4900\n",
      "epoch 28/30, average loss = 6.5577\n",
      "epoch 29/30, average loss = 6.2923\n",
      "epoch 30/30, average loss = 6.2692\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "model = ResNet34().to(device)\n",
    "\n",
    "# loss and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "# optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=0.001)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "# optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum = 0.9)\n",
    "#training loop\n",
    "n_total_steps = len(train)\n",
    "for epoch in range(num_epochs):\n",
    "    total_loss = 0\n",
    "    for i, (images, labels, cuttimes) in enumerate(train):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        cuttimes = cuttimes.to(device).float()\n",
    "\n",
    "        #forward\n",
    "        outputs = model(images, cuttimes)\n",
    "        # print(labels)\n",
    "        labels = labels.float() #this is the right code\n",
    "        # labels = float(labels[0][-17:-5])\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        #backward\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # if (i+1) % 1000 ==0:\n",
    "        # print(f'epoch {epoch+1}/{num_epochs}, step {i+1}/{n_total_steps}, loss = {loss.item():.4f}')\n",
    "        total_loss += loss.item()\n",
    "    print(f'epoch {epoch+1}/{num_epochs}, average loss = {total_loss/len(train):.4f}')\n",
    "            \n",
    "\n",
    "print(\"Finished Training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE = tensor([2.6635], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad(): # no need to calculate gradient\n",
    "    squared_difference = 0\n",
    "    for images, labels, cuttimes in test:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        cuttimes = cuttimes.to(device).float()\n",
    "        outputs = model(images, cuttimes)\n",
    "        predictions = float(outputs[0,0])\n",
    "\n",
    "        squared_difference += (predictions - labels) ** 2\n",
    "    \n",
    "    rmse = torch.sqrt(squared_difference / len(test))\n",
    "    print(f'RMSE = {rmse}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#consideration\n",
    "# 1. change the number of layers\n",
    "# 2. use GELU instead of ReLU"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
